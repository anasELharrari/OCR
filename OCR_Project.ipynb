{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe61b24-7dc4-4187-9f42-55c3a10890e4",
   "metadata": {},
   "source": [
    "# OCR-System for Arabic Handwritten words recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf12d807-4a97-4dd9-a14c-7ab6c166f44b",
   "metadata": {},
   "source": [
    "# Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c45b692-aac4-45df-8cd8-64eac248d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries to upload , process and pre-treat the data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# we define the Directory containing the images and we create an other directory named \"output_OCR\" to stock the pre-treated images\n",
    "image_dir = \"bmp\"\n",
    "output_dir=\"output_OCR\"\n",
    "\n",
    "# We create a list to store the loaded images\n",
    "loaded_images = []\n",
    "new_images=[]  #This list is created to be used later in this code to faciliate the treatment of data\n",
    "\n",
    "#Fixing a pre-defined width and height\n",
    "new_width = 224\n",
    "new_height = 224\n",
    "\n",
    "# Iterate over the files in the directory\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith(\".bmp\"): \n",
    "        file_path = os.path.join(image_dir, filename)\n",
    "        image = Image.open(file_path)\n",
    "        image = image.convert(\"RGB\")  #Converting the bmp images to RGB format\n",
    "        resized_image = image.resize((new_width, new_height)) #resizing the images\n",
    "        grayscale_image = resized_image.convert(\"L\")  #Converting them to grayscale images\n",
    "        loaded_images.append(grayscale_image)\n",
    "\n",
    "for image in loaded_images :        \n",
    "        if image.mode != \"L\":             #In this loop , we make sure that every image stored in loaded_images is in grayscale format \n",
    "            image = image.convert(\"L\")\n",
    "        \n",
    "        \n",
    "        # Convert image to NumPy array\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        \n",
    "        # Normalize the pixel values\n",
    "        normalized_image = (image_array.astype(np.float32) - 0) / 255.0\n",
    "        \n",
    "        # Convert the normalized image back to PIL image\n",
    "        normalized_image = (normalized_image * 255).astype(np.uint8)  # Convert back to appropriate data type\n",
    "        normalized_image = Image.fromarray(normalized_image)\n",
    "        \n",
    "        # Save the grayscale image\n",
    "        output_path = os.path.join(output_dir, filename[:-4] + \".png\")  # Change the extension to .png\n",
    "        normalized_image.save(output_path)\n",
    "        new_images.append(normalized_image)\n",
    "\n",
    "\n",
    "#for image in loaded_images:\n",
    "    #cv2.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e4f21a-ff5e-4631-9dda-c20655559f3b",
   "metadata": {},
   "source": [
    "## Extracting the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7aab6-b2f3-4427-b635-0c1f3d63bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------------------------All the labels exist in the \".tru\" files so we read ----------------------------------\n",
    "## ----------the files and ten we extract the label infomration from them using the following code------------------------\n",
    "\n",
    "#Specifing the directory of files\n",
    "label_dir = \"tru\"\n",
    "labels = []  #The labels gonna be storedd in this list\n",
    "\n",
    "#Iterate over the files in path\n",
    "for filename in os.listdir(label_dir):\n",
    "    if filename.endswith(\".tru\"):\n",
    "        file_path = os.path.join(label_dir, filename)\n",
    "        \n",
    "        # Read the contents of the label file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            \n",
    "            # Extract the label from the desired line\n",
    "            label = lines[6].strip()  \n",
    "            \n",
    "            # Add the label to the list\n",
    "            labels.append(label)\n",
    "\n",
    "#for label in labels:\n",
    "   # print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb919d4b-0a67-4c96-9e97-aa965e980a83",
   "metadata": {},
   "source": [
    "# Spliting Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbad48-c95d-4d20-8e83-2e916dcaf8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "#Spliting the data\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(new_images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the number of samples in each set\n",
    "print(\"Training set size:\", len(train_paths))\n",
    "print(\"Test set size:\", len(test_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11098292-958a-48c5-a2ca-33016190df6e",
   "metadata": {},
   "source": [
    "# Building the CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dbb149-8a19-419c-82b5-41f0c724062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------We build the CNN-model using the tansorflow libraries , this model is gonna used------------\n",
    "#-------------------------------------for spacial analysis of images-----------------------------------------------------\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "train_paths = np.asarray(train_paths) #Converting the training set images to numpy array\n",
    "train_paths = train_paths.tolist()\n",
    "#train_paths=train_paths.reshape(train_paths.shape[0],28,28,1)    #Reshaping the array to be suitable with CNN input\n",
    "train_labels = [str(label) for label in train_labels]  #Make sure that the labels are represented as strings\n",
    "\n",
    "\n",
    "# Define the CNN model\n",
    "model = keras.Sequential([\n",
    "    # Convolutional layers\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(new_height, new_width, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # Flatten the 2D feature maps to 1D\n",
    "    layers.Flatten(),\n",
    "    # Defining the fully connected layers\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(4, activation='relu') \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "#Fit the model\n",
    "model.fit(train_paths, train_labels, epochs=10, batch_size=32, validation_data=(train_paths,train_labels))\n",
    "#Save the model\n",
    "model.save('cnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ea6c59-e172-4faa-9a1f-8b4870fd470e",
   "metadata": {},
   "source": [
    "# Building the RNN-Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12513aca-b179-4a00-80f1-f1fb377bc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------The RNN-Model is used to extract the temporal dependencies in the sequencies for a better result generating---------\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "\n",
    "# Define the RNN model architecture\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(input_dim=455, output_dim=150, input_length=30))\n",
    "model1.add(SimpleRNN(units=100))\n",
    "model1.add(Dense(55, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model1.fit(train_paths, train_labels, epochs=10, batch_size=32, validation_data=(train_labels, train_labels))\n",
    "#Saving the model\n",
    "save_model(model1,'rnn_model.h5')\n",
    "# Evaluate the model\n",
    "loss, accuracy = model1.evaluate(test_paths,test_labels)\n",
    "\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b08935-49aa-4a4b-8b62-5d7312325c7f",
   "metadata": {},
   "source": [
    "# Connecting the CNN-model with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a30271-e192-4322-a5eb-31c581bdcdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#We load the both model that we saved before\n",
    "cnn_model = load_model('cnn_model.h5')\n",
    "rnn_model = load_model('rnn_model.h5')\n",
    "\n",
    "# we Prepare the input data\n",
    "preprocessed_input = preprocess_input(test_paths)  # Preprocess the input data for the CNN model\n",
    "\n",
    "# then we Pass the data through the cnn model\n",
    "cnn_features = cnn_model.predict(preprocessed_input)  \n",
    "\n",
    "# Preprocess the CNN features\n",
    "preprocessed_features = preprocess_features(cnn_features)  # In this step we are just making sure that the cnn output is suitable to\n",
    "#to be passed through the RNN-Model\n",
    "\n",
    "#Finally we Pass the preprocessed features into the RNN model and we make the prediction\n",
    "predictions = rnn_model.predict(preprocessed_features)  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "591f0756-a85f-4403-bd46-8088bd7fe613",
   "metadata": {},
   "source": [
    "Made by EL HARRARI Anas & ABDLLAOUI Mohamed "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
